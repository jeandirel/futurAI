{"question": "Which GDPR principle ensures only necessary data is collected for a purpose?", "options": ["Data minimization", "Accuracy", "Integrity and confidentiality", "Storage limitation"], "answer": "Data minimization", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "GDPR", "source": "instructions.pdf", "notes": "Basic definition."}
{"question": "In the EU AI Act, medical decision support typically falls under which risk category?", "options": ["Minimal risk", "Limited risk", "High risk", "Unacceptable risk"], "answer": "High risk", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "AI_Act", "source": "2526_Research_projects.pdf"}
{"question": "What is the main benefit of keeping prompts and outputs in a structured JSON schema?", "options": ["Reduces token cost", "Eases parsing and validation", "Improves model accuracy", "Encrypts the data"], "answer": "Eases parsing and validation", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Engineering", "source": "plan_developpement.md"}
{"question": "Why use pgvector with Postgres in this project?", "options": ["To compress PDFs", "To store embeddings for retrieval", "To host the frontend", "To manage user passwords"], "answer": "To store embeddings for retrieval", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "RAG", "source": "dev_technique.md"}
{"question": "If Validation detects two correct options in a MCQ, what should Healing do first?", "options": ["Lower the temperature", "Regenerate the question with stricter format constraints", "Add more options", "Ignore and pass to user"], "answer": "Regenerate the question with stricter format constraints", "bloom": "apply", "solo": "multistructural", "difficulty": "medium", "language": "en", "topic": "Workflow", "source": "plan_developpement.md"}
{"question": "Quelle metrique mesure l'ecart d'acceptation entre deux groupes pour la meme decision?", "options": ["Demographic parity difference", "RMSE", "BLEU score", "Latency p95"], "answer": "Demographic parity difference", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Fairness", "source": "Evaluation Grid.pdf"}
{"question": "Quand utiliser equalized odds comme metrique de fairness ?", "options": ["Quand seules les probabilites importent", "Quand on veut egaliser faux positifs et faux negatifs entre groupes", "Quand on veut mesurer la vitesse", "Quand on veut minimiser les couts"], "answer": "Quand on veut egaliser faux positifs et faux negatifs entre groupes", "bloom": "understand", "solo": "unistructural", "difficulty": "medium", "language": "fr", "topic": "Fairness", "source": "Evaluation Grid.pdf"}
{"question": "Le RAG doit injecter combien de passages pour limiter le bruit tout en gardant le contexte utile ?", "options": ["1 passage toujours", "3 a 5 passages pertinents", "10 passages minimum", "Tous les passages du document"], "answer": "3 a 5 passages pertinents", "bloom": "apply", "solo": "multistructural", "difficulty": "medium", "language": "fr", "topic": "RAG", "source": "dev_technique.md"}
{"question": "Quel risque principal apparait si on augmente trop la temperature du LLM pour generer des MCQ ?", "options": ["Plus de latence", "Plus d'hallucinations ou d'incoherences", "Moins de couts", "Plus de bonheur utilisateur"], "answer": "Plus d'hallucinations ou d'incoherences", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "LLM", "source": "dev_technique.md"}
{"question": "Quel est le but du filtrage PII avant ingestion ?", "options": ["Gagner du temps d'indexation", "Eviter de stocker des donnees personnelles", "Reduire la taille des chunks", "Ameliorer la syntaxe"], "answer": "Eviter de stocker des donnees personnelles", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Privacy", "source": "phase0_cadrage.md"}
{"question": "What does latency p95 represent in system metrics?", "options": ["Average latency", "Minimum latency", "Latency below which 95% of requests fall", "Maximum observed latency"], "answer": "Latency below which 95% of requests fall", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "SRE", "source": "plan_developpement.md"}
{"question": "Why keep FR/EN balance in the gold dataset?", "options": ["To reduce storage size", "To avoid language bias during evaluation", "To increase latency", "To simplify prompts"], "answer": "To avoid language bias during evaluation", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Fairness", "source": "phase1_donnees_annotation.md"}
{"question": "What is the main benefit of structured logging (JSON) for agents?", "options": ["Reduces GPU cost", "Facilitates parsing, search, and monitoring", "Encrypts data at rest", "Adds more colors to logs"], "answer": "Facilitates parsing, search, and monitoring", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Observability", "source": "dev_technique.md"}
{"question": "Quelle action prendre si une question semble stereotypee culturellement ?", "options": ["La valider quand meme", "Demander rephrasing contraint et verifier avec Equite", "Augmenter la temperature", "Supprimer le feedback"], "answer": "Demander rephrasing contraint et verifier avec Equite", "bloom": "apply", "solo": "multistructural", "difficulty": "medium", "language": "fr", "topic": "Fairness", "source": "dev_technique.md"}
{"question": "Quel objectif SOLO correspond a relier plusieurs idees dans une seule reponse coherente ?", "options": ["Prestructural", "Unistructural", "Relational", "Extended"], "answer": "Relational", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "SOLO", "source": "plan_developpement.md"}
{"question": "Which step should happen before calling the LLM in Generation?", "options": ["Collect metrics", "Retrieve context chunks from the vector index", "Render the frontend", "Compress the database"], "answer": "Retrieve context chunks from the vector index", "bloom": "apply", "solo": "multistructural", "difficulty": "medium", "language": "en", "topic": "RAG", "source": "dev_technique.md"}
{"question": "When should a fallback model be used?", "options": ["When the main LLM is slow or fails twice", "Always, for every request", "Only for admin users", "Never, it increases cost"], "answer": "When the main LLM is slow or fails twice", "bloom": "apply", "solo": "multistructural", "difficulty": "medium", "language": "en", "topic": "LLM", "source": "dev_technique.md"}
{"question": "Quel est le risque si le chunking est trop grand ?", "options": ["Perte de contexte", "Cout tokens plus eleve et bruit contextuel", "Pas de recuperation", "Plus de GPU"], "answer": "Cout tokens plus eleve et bruit contextuel", "bloom": "understand", "solo": "unistructural", "difficulty": "medium", "language": "fr", "topic": "RAG", "source": "dev_technique.md"}
{"question": "Pourquoi verifier la presence de deux reponses correctes dans un MCQ ?", "options": ["Pour augmenter la difficulte", "Pour eviter ambiguite et noter justement", "Pour reduire la longueur", "Pour economiser des tokens"], "answer": "Pour eviter ambiguite et noter justement", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Validation", "source": "plan_taches.md"}
{"question": "What is the first mitigation if toxicity is detected in feedback?", "options": ["Ignore it", "Regenerate with stricter safety prompt and lower temperature", "Add more options", "Store it unfiltered"], "answer": "Regenerate with stricter safety prompt and lower temperature", "bloom": "apply", "solo": "multistructural", "difficulty": "medium", "language": "en", "topic": "Safety", "source": "dev_technique.md"}
{"question": "Which Bloom level focuses on recalling facts?", "options": ["Remember", "Apply", "Analyze", "Create"], "answer": "Remember", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Bloom", "source": "plan_developpement.md"}
{"question": "Quel niveau Bloom demande d'expliquer des idees avec ses propres mots ?", "options": ["Remember", "Understand", "Analyze", "Evaluate"], "answer": "Understand", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Bloom", "source": "plan_developpement.md"}
{"question": "Quel niveau SOLO correspond a 'unistructural' ?", "options": ["Une seule idee simple", "Plusieurs idees reliees", "Aucune idee", "Idees reliees en profondeur"], "answer": "Une seule idee simple", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "SOLO", "source": "plan_developpement.md"}
{"question": "In the pipeline, which agent delivers explanations to students?", "options": ["Generation", "Validation", "Feedback", "Healing"], "answer": "Feedback", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Architecture", "source": "definion.md"}
{"question": "Quel agent est responsable de detecter et corriger les erreurs automatiques ?", "options": ["Generation", "Healing", "Equite", "Archiviste"], "answer": "Healing", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Architecture", "source": "definion.md"}
{"question": "Pourquoi journaliser chaque action des agents ?", "options": ["Augmenter la taille des logs", "Rendre le debug et la tracabilite possibles", "Reduire la latence", "Eviter d'utiliser Redis"], "answer": "Rendre le debug et la tracabilite possibles", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Observability", "source": "dev_technique.md"}
{"question": "What should be stored in `data/annotations/mcq_gold.jsonl`?", "options": ["Raw PDFs", "Labeled MCQ items with Bloom/SOLO", "Frontend assets", "Docker images"], "answer": "Labeled MCQ items with Bloom/SOLO", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Data", "source": "phase1_donnees_annotation.md"}
{"question": "Quel format utiliser pour les annotations MCQ ?", "options": ["CSV avec colonnes libres", "JSONL avec schema question/options/reponse/labels", "Images", "HTML"], "answer": "JSONL avec schema question/options/reponse/labels", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Data", "source": "phase1_donnees_annotation.md"}
{"question": "How many attempts should Healing try before failing a job?", "options": ["0", "1", "2-3 with backoff", "Unlimited"], "answer": "2-3 with backoff", "bloom": "apply", "solo": "multistructural", "difficulty": "medium", "language": "en", "topic": "Workflow", "source": "plan_developpement.md"}
{"question": "Quel indicateur surveiller pour savoir si le LLM est trop lent ?", "options": ["NPS", "Latency p95", "Couverture test", "Nombre de slides"], "answer": "Latency p95", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "SRE", "source": "plan_developpement.md"}
{"question": "Which metric compares true positive and false positive rates across groups?", "options": ["Equalized odds difference", "RMSE", "Perplexity", "F1-score"], "answer": "Equalized odds difference", "bloom": "remember", "solo": "unistructural", "difficulty": "medium", "language": "en", "topic": "Fairness", "source": "Evaluation Grid.pdf"}
{"question": "Quelle est la meilleure pratique pour eviter les PII lors du chunking ?", "options": ["Augmenter la temperature", "Filtrer et anonymiser avant index", "Ignorer les chunks longs", "Utiliser des emojis"], "answer": "Filtrer et anonymiser avant index", "bloom": "apply", "solo": "multistructural", "difficulty": "medium", "language": "fr", "topic": "Privacy", "source": "phase0_cadrage.md"}
{"question": "Why copy manifest.csv to processed outputs?", "options": ["To reduce latency", "To keep traceability of ingested files", "To minify JSON", "To improve accuracy"], "answer": "To keep traceability of ingested files", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Data", "source": "scripts/extract_pdf_text.py"}
{"question": "Quel est le role d'un fallback open-source dans ce projet ?", "options": ["Remplacer la base Postgres", "Servir de secours si le LLM principal echoue", "Heberger le frontend", "Supprimer les logs"], "answer": "Servir de secours si le LLM principal echoue", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "LLM", "source": "dev_technique.md"}
{"question": "What kind of queue is recommended for coordinating agents?", "options": ["Email", "Redis/Celery", "FTP", "Excel"], "answer": "Redis/Celery", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Architecture", "source": "dev_technique.md"}
{"question": "Quel fichier contient la liste des biais potentiels ?", "options": ["plan_taches.md", "biais_initiaux.md", "README.md", "Dockerfile"], "answer": "biais_initiaux.md", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Fairness", "source": "docs/biais_initiaux.md"}
{"question": "Pourquoi equilibrer la difficulte des MCQ dans le jeu gold ?", "options": ["Pour reduire la taille du fichier", "Pour couvrir plusieurs niveaux d'apprentissage", "Pour augmenter la latence", "Pour eviter l'anglais"], "answer": "Pour couvrir plusieurs niveaux d'apprentissage", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Assessment", "source": "phase1_donnees_annotation.md"}
{"question": "Which step ensures MCQ format consistency?", "options": ["Frontend rendering", "Validation agent checks structure and unique answer", "Equite scanning", "Redis persistence"], "answer": "Validation agent checks structure and unique answer", "bloom": "understand", "solo": "unistructural", "difficulty": "medium", "language": "en", "topic": "Validation", "source": "plan_taches.md"}
{"question": "Quel agent gere les supports et l'index vectoriel ?", "options": ["Archiviste/KG", "Equite", "Feedback", "Docteur"], "answer": "Archiviste/KG", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Architecture", "source": "dev_technique.md"}
{"question": "Why use chunking during ingestion?", "options": ["To translate documents", "To split documents into manageable pieces for embeddings", "To encrypt data", "To render slides"], "answer": "To split documents into manageable pieces for embeddings", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "RAG", "source": "dev_technique.md"}
{"question": "Quelle metrique suivre pour la fiabilite healing ?", "options": ["Taux de succes de regeneration", "Nombre de slides", "Taille du manifest", "Nombre d'images"], "answer": "Taux de succes de regeneration", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Healing", "source": "plan_developpement.md"}
{"question": "What is the purpose of retries with backoff?", "options": ["Increase cost", "Handle transient failures gracefully", "Remove logs", "Speed up every request"], "answer": "Handle transient failures gracefully", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Reliability", "source": "dev_technique.md"}
{"question": "Quel est l'avantage principal d'un dashboard pour les metriques ?", "options": ["Rendre les PDF plus lisibles", "Visualiser latence, healing et fairness en temps reel", "Reduire la taille des donnees", "Eviter les tests"], "answer": "Visualiser latence, healing et fairness en temps reel", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Dashboard", "source": "dev_technique.md"}
{"question": "Which SOLO level corresponds to building deep connections between ideas?", "options": ["Extended", "Unistructural", "Prestructural", "Multistructural"], "answer": "Extended", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "SOLO", "source": "plan_developpement.md"}
{"question": "Comment traiter une page PDF dont l'extraction a echoue ?", "options": ["Ignorer et logguer l'avertissement", "Supprimer le PDF", "Rendre le frontend", "Forcer la traduction"], "answer": "Ignorer et logguer l'avertissement", "bloom": "apply", "solo": "multistructural", "difficulty": "medium", "language": "fr", "topic": "Ingestion", "source": "scripts/extract_pdf_text.py"}
{"question": "Why avoid including PII in the index?", "options": ["It increases latency", "It violates privacy and compliance", "It improves accuracy", "It speeds up queries"], "answer": "It violates privacy and compliance", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Privacy", "source": "phase0_cadrage.md"}
{"question": "Quel agent doit verifier la toxicite des feedbacks ?", "options": ["Validation", "Equite", "Generation", "Archiviste"], "answer": "Equite", "bloom": "remember", "solo": "unistructural", "difficulty": "medium", "language": "fr", "topic": "Fairness", "source": "plan_taches.md"}
{"question": "Which document lists the overall project tasks and phases?", "options": ["definion.md", "plan_taches.md", "manifest.csv", "Dockerfile"], "answer": "plan_taches.md", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Project", "source": "plan_taches.md"}
{"question": "Quel est le risque de laisser des options tres similaires dans un MCQ ?", "options": ["Latence elevee", "Confusion et biais de discrimination", "Moins de tokens", "Plus de couleurs"], "answer": "Confusion et biais de discrimination", "bloom": "understand", "solo": "unistructural", "difficulty": "medium", "language": "fr", "topic": "Assessment", "source": "Validation best practice"}
{"question": "What is a reasonable chunk size for embeddings?", "options": ["32 tokens", "512-1024 tokens", "10,000 tokens", "No chunking"], "answer": "512-1024 tokens", "bloom": "remember", "solo": "unistructural", "difficulty": "medium", "language": "en", "topic": "RAG", "source": "dev_technique.md"}
{"question": "Pourquoi utiliser un schema Pydantic pour les messages ?", "options": ["Pour styliser le frontend", "Pour valider et typer les payloads", "Pour augmenter la latence", "Pour supprimer les logs"], "answer": "Pour valider et typer les payloads", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Backend", "source": "dev_technique.md"}
{"question": "Which fairness metric checks the difference in selection rates across groups?", "options": ["Demographic parity difference", "RMSE", "Logloss", "BLEU"], "answer": "Demographic parity difference", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Fairness", "source": "Evaluation Grid.pdf"}
{"question": "Quel parametre surveiller pour l'equite linguistique ?", "options": ["Temps GPU", "Taux d'acceptation par langue", "Nombre de containers", "Taille du manifest"], "answer": "Taux d'acceptation par langue", "bloom": "understand", "solo": "unistructural", "difficulty": "medium", "language": "fr", "topic": "Fairness", "source": "phase1_donnees_annotation.md"}
{"question": "Why use Redis in this architecture?", "options": ["Serve static files", "Queue tasks between agents", "Host the frontend", "Encrypt data at rest"], "answer": "Queue tasks between agents", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Architecture", "source": "dev_technique.md"}
{"question": "Quel niveau Bloom correspond a la creation de nouvelles idees ?", "options": ["Create", "Remember", "Apply", "Analyze"], "answer": "Create", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Bloom", "source": "plan_developpement.md"}
{"question": "What is the role of `data/processed/`?", "options": ["Store raw PDFs", "Store extracted/plaintext versions for indexing", "Store Docker images", "Host frontend builds"], "answer": "Store extracted/plaintext versions for indexing", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Data", "source": "scripts/extract_pdf_text.py"}
{"question": "Quel fichier liste les documents sources ingeres ?", "options": ["manifest.csv", "plan_taches.md", "README.md", "definion.md"], "answer": "manifest.csv", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Data", "source": "data/raw/manifest.csv"}
{"question": "Which agent should trigger a regeneration when fairness thresholds are exceeded?", "options": ["Feedback", "Healing", "Archiviste", "Frontend"], "answer": "Healing", "bloom": "apply", "solo": "multistructural", "difficulty": "medium", "language": "en", "topic": "Fairness", "source": "plan_taches.md"}
{"question": "Quel est le but du rerank apres un kNN sur l'index vectoriel ?", "options": ["Melanger les resultats", "Ameliorer la pertinence des passages selectionnes", "Reduire la taille des logs", "Augmenter la temperature"], "answer": "Ameliorer la pertinence des passages selectionnes", "bloom": "understand", "solo": "unistructural", "difficulty": "medium", "language": "fr", "topic": "RAG", "source": "dev_technique.md"}
{"question": "Why is a balanced gold set important for evaluation?", "options": ["To increase cost", "To get representative metrics across topics and languages", "To slow down CI", "To avoid JSON"], "answer": "To get representative metrics across topics and languages", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Evaluation", "source": "phase1_donnees_annotation.md"}
{"question": "Quel type de test verifiera le pipeline complet Generation->Validation->Feedback->Healing ?", "options": ["Test unitaire", "Test d'integration end-to-end", "Test visuel", "Test manuel uniquement"], "answer": "Test d'integration end-to-end", "bloom": "remember", "solo": "unistructural", "difficulty": "medium", "language": "fr", "topic": "Tests", "source": "plan_taches.md"}
{"question": "Which metric should be tracked for healing success?", "options": ["GPU usage", "Healing success rate", "Number of slides", "Manifest size"], "answer": "Healing success rate", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Healing", "source": "plan_developpement.md"}
{"question": "Quel est le risque d'un manque de double lecture sur les annotations ?", "options": ["Baisse de latence", "Incoherence des labels et biais dans le gold set", "Plus de GPU", "Moins de documents"], "answer": "Incoherence des labels et biais dans le gold set", "bloom": "understand", "solo": "unistructural", "difficulty": "medium", "language": "fr", "topic": "Annotation", "source": "phase1_donnees_annotation.md"}
{"question": "When should chunk metadata include language?", "options": ["Always, to support multi-language retrieval and fairness checks", "Never", "Only for images", "Only for prod"], "answer": "Always, to support multi-language retrieval and fairness checks", "bloom": "apply", "solo": "multistructural", "difficulty": "medium", "language": "en", "topic": "RAG", "source": "dev_technique.md"}
{"question": "Que mesurer pour detecter un biais de longueur d'enonce ?", "options": ["Temps GPU", "Distribution des longueurs par langue/groupe", "Nombre de pods", "Taille des logs"], "answer": "Distribution des longueurs par langue/groupe", "bloom": "apply", "solo": "multistructural", "difficulty": "medium", "language": "fr", "topic": "Fairness", "source": "biais_initiaux.md"}
{"question": "Which field in MCQ schema links to the course source?", "options": ["topic", "answer", "notes", "language"], "answer": "topic", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Data", "source": "phase1_donnees_annotation.md"}
{"question": "Pourquoi noter les cas limites de biais des le depart ?", "options": ["Pour ralentir le projet", "Pour cibler les metriques et mitigations pertinentes", "Pour supprimer des questions", "Pour eviter les logs"], "answer": "Pour cibler les metriques et mitigations pertinentes", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Fairness", "source": "biais_initiaux.md"}
{"question": "Which principle of GDPR limits how long data is kept?", "options": ["Storage limitation", "Data minimization", "Integrity", "Accuracy"], "answer": "Storage limitation", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "GDPR", "source": "instructions.pdf"}
{"question": "Quel risque est associe a l'utilisation de donnees non anonymisees ?", "options": ["Baisse de latence", "Violation de la vie privee et conformite", "Moins de tokens", "Plus de GPU"], "answer": "Violation de la vie privee et conformite", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Privacy", "source": "phase0_cadrage.md"}
{"question": "What is the purpose of a seed MCQ file?", "options": ["Store raw PDFs", "Provide initial examples for validation or bootstrapping", "Serve frontend assets", "Hold Docker configs"], "answer": "Provide initial examples for validation or bootstrapping", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Annotation", "source": "phase1_donnees_annotation.md"}
{"question": "Quel indicateur surveiller pour l'equite de toxicite ?", "options": ["Toxicity rate diff par groupe/langue", "Nombre de pods", "Taille des PDFs", "Longueur des logs"], "answer": "Toxicity rate diff par groupe/langue", "bloom": "remember", "solo": "unistructural", "difficulty": "medium", "language": "fr", "topic": "Fairness", "source": "Evaluation Grid.pdf"}
{"question": "Which component handles authentication/security in fastapi skeleton?", "options": ["core/", "agents/", "schemas/", "data/"], "answer": "core/", "bloom": "remember", "solo": "unistructural", "difficulty": "medium", "language": "en", "topic": "Backend", "source": "dev_technique.md"}
{"question": "Quel est le but de backups Postgres quotidiens ?", "options": ["Ajouter des couleurs au frontend", "Assurer la retention et la reprise apres incident", "Reduire la latence", "Supprimer les logs"], "answer": "Assurer la retention et la reprise apres incident", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Ops", "source": "dev_technique.md"}
{"question": "Why is a CLI mode useful?", "options": ["To bypass tests", "To run reproducible batch tests offline", "To slow the system", "To replace the frontend"], "answer": "To run reproducible batch tests offline", "bloom": "understand", "solo": "unistructural", "difficulty": "medium", "language": "en", "topic": "UX", "source": "plan_taches.md"}
{"question": "Quel est l'objectif principal du module Equite ?", "options": ["Rendre le frontend plus joli", "Scanner toxicite/stereotypes et produire scores fairness", "Augmenter la latence", "Compresser les logs"], "answer": "Scanner toxicite/stereotypes et produire scores fairness", "bloom": "remember", "solo": "unistructural", "difficulty": "medium", "language": "fr", "topic": "Fairness", "source": "dev_technique.md"}
{"question": "Which metric indicates quiz acceptance quality?", "options": ["Acceptance rate after Validation", "Number of PPTX files", "GPU memory", "Manifest size"], "answer": "Acceptance rate after Validation", "bloom": "remember", "solo": "unistructural", "difficulty": "medium", "language": "en", "topic": "Quality", "source": "plan_developpement.md"}
{"question": "Pourquoi ajouter des notes dans les annotations MCQ ?", "options": ["Reduire la taille", "Justifier les choix et aider a la revue", "Augmenter la latence", "Enlever des options"], "answer": "Justifier les choix et aider a la revue", "bloom": "understand", "solo": "unistructural", "difficulty": "medium", "language": "fr", "topic": "Annotation", "source": "phase1_donnees_annotation.md"}
{"question": "What is a key output of Phase 1 besides the gold set?", "options": ["Docker images", "List of initial biases and edge cases", "Frontend theme", "K8s manifests"], "answer": "List of initial biases and edge cases", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Fairness", "source": "biais_initiaux.md"}
{"question": "Quel est l'objectif d'un rerun automatique du Healing ?", "options": ["Augmenter la latence", "Corriger erreurs sans intervention humaine", "Supprimer les logs", "Reduire le nombre d'options"], "answer": "Corriger erreurs sans intervention humaine", "bloom": "understand", "solo": "unistructural", "difficulty": "medium", "language": "fr", "topic": "Healing", "source": "plan_developpement.md"}
{"question": "Which file documents technical stack and architecture?", "options": ["dev_technique.md", "definion.md", "manifest.csv", "mcq_seed.jsonl"], "answer": "dev_technique.md", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Documentation", "source": "dev_technique.md"}
{"question": "Quel est le role principal du dashboard ?", "options": ["Afficher des memes", "Suivre jobs, runs, metriques et alertes", "Stocker les PDF", "Compiler du code"], "answer": "Suivre jobs, runs, metriques et alertes", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Dashboard", "source": "dev_technique.md"}
{"question": "Why track topic metadata on MCQ items?", "options": ["To drop data", "To align questions with course chapters and evaluation splits", "To slow ingestion", "To encrypt storage"], "answer": "To align questions with course chapters and evaluation splits", "bloom": "understand", "solo": "unistructural", "difficulty": "medium", "language": "en", "topic": "Data", "source": "phase1_donnees_annotation.md"}
{"question": "Quel est le principal avantage de tests de charge precoces ?", "options": ["Augmenter le cout", "Detecter les goulets de latence avant la prod", "Reduire le nombre de questions", "Enlever les logs"], "answer": "Detecter les goulets de latence avant la prod", "bloom": "understand", "solo": "unistructural", "difficulty": "medium", "language": "fr", "topic": "Performance", "source": "plan_developpement.md"}
{"question": "Which fairness metric suits toxicity comparison across groups?", "options": ["Toxicity rate difference", "BLEU", "RMSE", "Latency p95"], "answer": "Toxicity rate difference", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Fairness", "source": "Evaluation Grid.pdf"}
{"question": "Pourquoi utiliser un rerank optionnel apres RAG ?", "options": ["Augmenter la latence volontairement", "Ameliorer la pertinence contextuelle", "Reduire le nombre d'agents", "Supprimer les chunks"], "answer": "Ameliorer la pertinence contextuelle", "bloom": "understand", "solo": "unistructural", "difficulty": "medium", "language": "fr", "topic": "RAG", "source": "dev_technique.md"}
{"question": "What should be the next step after collecting PDFs in data/raw?", "options": ["Delete them", "Extract text to data/processed", "Push to production", "Ignore RAG"], "answer": "Extract text to data/processed", "bloom": "apply", "solo": "multistructural", "difficulty": "easy", "language": "en", "topic": "Ingestion", "source": "scripts/extract_pdf_text.py"}
{"question": "Quel type de metrique refleterait une penalite injuste pour un groupe ?", "options": ["Equalized odds diff elevee", "Latence faible", "Couverture de test", "Taille de la BD"], "answer": "Equalized odds diff elevee", "bloom": "understand", "solo": "unistructural", "difficulty": "medium", "language": "fr", "topic": "Fairness", "source": "Evaluation Grid.pdf"}
{"question": "Why keep options length between 3 and 6 items?", "options": ["To respect best practices for MCQ clarity", "To increase token cost", "To improve GPU usage", "To reduce fairness"], "answer": "To respect best practices for MCQ clarity", "bloom": "understand", "solo": "multistructural", "difficulty": "medium", "language": "en", "topic": "Assessment", "source": "Validation guidance"}
{"question": "Quel est le role d'un schema JSON pour les prompts ?", "options": ["Ajouter des couleurs", "Imposer le format de sortie pour parsing fiable", "Reduire la longueur des documents", "Remplacer Redis"], "answer": "Imposer le format de sortie pour parsing fiable", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "LLM", "source": "dev_technique.md"}
{"question": "What is the main mitigation for hallucinations detected in validation?", "options": ["Ignore", "Regenerate with stricter constraints and context", "Raise temperature", "Remove options"], "answer": "Regenerate with stricter constraints and context", "bloom": "apply", "solo": "multistructural", "difficulty": "medium", "language": "en", "topic": "Healing", "source": "plan_developpement.md"}
{"question": "Pourquoi conserver un historique des runs dans la base ?", "options": ["Augmenter la taille", "Permettre audit, debug et metriques", "Reduire la latence", "Supprimer le frontend"], "answer": "Permettre audit, debug et metriques", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Observability", "source": "dev_technique.md"}
{"question": "Which SOLO level requires linking ideas across multiple aspects?", "options": ["Relational", "Prestructural", "Unistructural", "Multistructural"], "answer": "Relational", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "SOLO", "source": "plan_developpement.md"}
{"question": "Quel KPI suivre pour la satisfaction utilisateur ?", "options": ["NPS", "Nombre de pods", "Taille des logs", "Manifest size"], "answer": "NPS", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "UX", "source": "plan_developpement.md"}
{"question": "What is the goal of double-reading a subset of annotations?", "options": ["Increase latency", "Reduce label noise and align guidelines", "Remove gold items", "Avoid JSON"], "answer": "Reduce label noise and align guidelines", "bloom": "understand", "solo": "unistructural", "difficulty": "medium", "language": "en", "topic": "Annotation", "source": "phase1_donnees_annotation.md"}
{"question": "Quel est l'avantage d'avoir un seed MCQ pour bootstrap ?", "options": ["Eviter la validation", "Servir de reference rapide pour tests initiaux", "Supprimer les PDFs", "Reduire la latence"], "answer": "Servir de reference rapide pour tests initiaux", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Annotation", "source": "phase1_donnees_annotation.md"}
{"question": "Which metric tracks overall alignment quality?", "options": ["F1 Bloom/SOLO", "Docker image size", "GPU clock", "Manifest rows"], "answer": "F1 Bloom/SOLO", "bloom": "remember", "solo": "unistructural", "difficulty": "medium", "language": "en", "topic": "Evaluation", "source": "plan_developpement.md"}
{"question": "Pourquoi equilibrer les sujets dans le jeu gold ?", "options": ["Augmenter la latence", "Eviter qu'un seul chapitre domine l'evaluation", "Supprimer des options", "Reduire les logs"], "answer": "Eviter qu'un seul chapitre domine l'evaluation", "bloom": "understand", "solo": "unistructural", "difficulty": "medium", "language": "fr", "topic": "Evaluation", "source": "phase1_donnees_annotation.md"}
{"question": "What should be avoided in options to reduce bias?", "options": ["Neutral language without stereotypes", "Cultural stereotypes or gendered wording", "Clear wording", "Balanced difficulty"], "answer": "Cultural stereotypes or gendered wording", "bloom": "remember", "solo": "unistructural", "difficulty": "medium", "language": "en", "topic": "Fairness", "source": "biais_initiaux.md"}
{"question": "Quel est le point de controle pour la toxicite des feedbacks ?", "options": ["Validation", "Equite", "Archiviste", "Frontend"], "answer": "Equite", "bloom": "remember", "solo": "unistructural", "difficulty": "medium", "language": "fr", "topic": "Fairness", "source": "plan_taches.md"}
{"question": "Why log skipped files during extraction?", "options": ["To ignore them", "To know which non-PDFs weren't processed", "To speed up LLM", "To reduce disk usage"], "answer": "To know which non-PDFs weren't processed", "bloom": "understand", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Ingestion", "source": "scripts/extract_pdf_text.py"}
{"question": "Quel fichier decrit les publics et langues cibles ?", "options": ["phase0_cadrage.md", "manifest.csv", "README.md", "Dockerfile"], "answer": "phase0_cadrage.md", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "fr", "topic": "Cadrage", "source": "phase0_cadrage.md"}
{"question": "Which process ensures fairness metrics are visualized?", "options": ["Dashboard charts for demographic parity/equalized odds/toxicity", "Deleting logs", "Skipping RAG", "Hardcoding answers"], "answer": "Dashboard charts for demographic parity/equalized odds/toxicity", "bloom": "apply", "solo": "multistructural", "difficulty": "medium", "language": "en", "topic": "Fairness", "source": "dev_technique.md"}
{"question": "Pourquoi inclure la langue dans chaque item MCQ ?", "options": ["Pour traduire automatiquement", "Pour mesurer et filtrer les performances/fairness par langue", "Pour reduire les logs", "Pour compresser la BD"], "answer": "Pour mesurer et filtrer les performances/fairness par langue", "bloom": "understand", "solo": "unistructural", "difficulty": "medium", "language": "fr", "topic": "Fairness", "source": "phase1_donnees_annotation.md"}
{"question": "What is the purpose of `scripts/validate_mcq_jsonl.py`?", "options": ["Render frontend", "Check schema of MCQ JSONL files", "Run Redis", "Deploy Docker"], "answer": "Check schema of MCQ JSONL files", "bloom": "remember", "solo": "unistructural", "difficulty": "easy", "language": "en", "topic": "Tooling", "source": "scripts/README.md"}
{"question": "Quel est le principal risque d'un index vectoriel non versionne ?", "options": ["Perte de contexte et incoherence avec les docs", "Latency reduite", "Plus de GPU", "Options plus courtes"], "answer": "Perte de contexte et incoherence avec les docs", "bloom": "understand", "solo": "unistructural", "difficulty": "medium", "language": "fr", "topic": "RAG", "source": "dev_technique.md"}
